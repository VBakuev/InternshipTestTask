{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "oUnakYNVfo5Z",
    "outputId": "e8e2359d-9776-4627-f4e2-1451c4895f1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Подключение ноутбука к google.colab \"\"\"\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "id": "CqAWsn6Tgbs9",
    "outputId": "a96e539c-c379-4330-8d21-d903b0cc8e68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboardX\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/12/dcaf67e1312475b26db9e45e7bb6f32b540671a9ee120b3a72d9e09bc517/tensorboardX-1.8-py2.py3-none-any.whl (216kB)\n",
      "\r",
      "\u001b[K     |█▌                              | 10kB 19.7MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 20kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 30kB 2.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 40kB 1.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 51kB 2.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 61kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 71kB 2.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 81kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 92kB 3.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 102kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 112kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 122kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 133kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 143kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 153kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 163kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 174kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 184kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 194kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 204kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 215kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 225kB 2.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.16.5)\n",
      "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.7.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX) (41.2.0)\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-1.8\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Подключение tensorboardX \"\"\"\n",
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "V7gNceLfgK1a",
    "outputId": "c1d26359-3df8-43cf-86e8-17005400511d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/humans/data\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/My Drive/humans/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbcSOMUlfkOk"
   },
   "outputs": [],
   "source": [
    "\"\"\" Подкдючение необходимых библеотек \"\"\"\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import PIL\n",
    "import torch.utils.data as dt\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "to_img = ToPILImage()\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import *\n",
    "import numpy as np\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lib import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E3IEEJ1bfkO_"
   },
   "outputs": [],
   "source": [
    "DEVICE_ID = 0\n",
    "DEVICE = torch.device('cuda:%d' % DEVICE_ID)\n",
    "torch.cuda.set_device(DEVICE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JiVe2hN7tuei"
   },
   "outputs": [],
   "source": [
    "class HumanDataset(dt.Dataset):\n",
    "    \"\"\" \n",
    "        Human features dataset.  Override torch Dataset class to implements reading from h5 files\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_path, mask_path):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_path (string): Path to the images data files.\n",
    "            mask_path (string): Path were images masks are placed\n",
    "        \"\"\"\n",
    "        self.files = os.listdir(data_path)\n",
    "        self.files.sort()\n",
    "        self.mask_files = os.listdir(mask_path)\n",
    "        self.mask_files.sort()\n",
    "        self.data_path = data_path\n",
    "        self.mask_path = mask_path\n",
    "        assert (len(self.files) == len(self.mask_files))\n",
    "        self.preprocess = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TlaytnQPY0-U"
   },
   "outputs": [],
   "source": [
    "\"\"\" Подключение датасетов \"\"\" \n",
    "ds = HumanDataset(train, train_mask) \n",
    "ds_test = HumanDataset(test, test)\n",
    "ds_valid = HumanDataset(valid, valid_mask) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4wLVKTg7yJYJ"
   },
   "outputs": [],
   "source": [
    "net = SegmenterModel1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j3koFAVepXZJ"
   },
   "outputs": [],
   "source": [
    "\"\"\" Класс SoftDiceLoss (Dice coefficient). Используется в обучении сети как метрика \"\"\"\n",
    "class SoftDiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(SoftDiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        smooth = 1e-5\n",
    "        num = targets.size(0)\n",
    "        probs = F.sigmoid(logits)\n",
    "        m1 = probs.view(num, -1)\n",
    "        m2 = targets.view(num, -1)\n",
    "        intersection = (m1 * m2)\n",
    "        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\n",
    "        score = 1 - score.sum() / num\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Geu4MNC-GbKt"
   },
   "outputs": [],
   "source": [
    "   \"\"\" Обучение сети\"\"\"\n",
    "    \n",
    "    useCuda =True\n",
    "    n_epoch = 50\n",
    "    log = './log/'\n",
    "    train = './train/'\n",
    "    train_masks = './train_mask/'\n",
    "    valid = './valid/'\n",
    "    valid_masks = './valid_mask'\n",
    "    tb_writer = SummaryWriter(log_dir='log')\n",
    "    \n",
    "    m = SegmenterModel1()\n",
    "    \n",
    "    \"\"\" Выбор критерия оценки и оптимизатора \"\"\"\n",
    "    \n",
    "    criterion = SoftDiceLoss()\n",
    "    optimizer = optim.Adam(m.parameters(), lr=0.0001)\n",
    "\n",
    "    if useCuda == True:\n",
    "        m = m.cuda()\n",
    "        criterion= criterion.cuda()\n",
    "        \n",
    "    \"\"\" Подключение загрузчиков \"\"\"\n",
    "    \n",
    "    dl      = dt.DataLoader(ds, shuffle=True, num_workers=4, batch_size=5)\n",
    "    dl_valid = dt.DataLoader(ds_valid, shuffle=False, num_workers=4, batch_size=5)\n",
    "    \n",
    "    \"\"\" Процесс обучения\"\"\"\n",
    "\n",
    "    global_iter = 0\n",
    "    for epoch in range(0, n_epoch):\n",
    "        print (\"Current epoch: \", epoch)\n",
    "        epoch_loss = 0\n",
    "        m.train(True)\n",
    "        for iter, (i, t) in enumerate(tqdm( dl) ):\n",
    "            i = Variable(i)\n",
    "            t = Variable(t)\n",
    "            if useCuda :\n",
    "                i = i.cuda()\n",
    "                t = t.cuda()\n",
    "            o = m(i)\n",
    "            loss = criterion(o, t)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            global_iter += 1\n",
    "            epoch_loss += loss.data\n",
    "\n",
    "        epoch_loss = epoch_loss / float(len(ds))\n",
    "        print (\"Epoch loss\", epoch_loss)\n",
    "        tb_writer.add_scalar('Loss/Train', epoch_loss, epoch)\n",
    "\n",
    "        print (\"Make valid\")\n",
    "        valid_loss = 0\n",
    "        m.train(False)\n",
    "\n",
    "        tb_out = np.random.choice(range(0, len(dl_valid)), 3 )\n",
    "        for iter, (i, t) in enumerate(tqdm(dl_valid)):\n",
    "            i = Variable(i, volatile = True)\n",
    "            t = Variable(t, volatile = True)\n",
    "            if useCuda :\n",
    "                i = i.cuda()\n",
    "                t = t.cuda()\n",
    "            o = m(i)\n",
    "            loss = criterion(o, t)\n",
    "            valid_loss += loss.data\n",
    "\n",
    "            for k, c in enumerate(tb_out):\n",
    "                if c == iter:\n",
    "                    tb_writer.add_image('Image/Test_input_%d'%k,  i[0].cpu(), epoch)  # Tensor\n",
    "                    tb_writer.add_image('Image/Test_target_%d'%k, t[0].cpu(), epoch)  # Tensor\n",
    "                    tb_writer.add_image('Image/Test_output_%d'%k, o[0].cpu(), epoch)  # Tensor\n",
    "\n",
    "        valid_loss = valid_loss / float(len(ds_test))\n",
    "        print (\"Valid loss\", valid_loss)\n",
    "        tb_writer.add_scalar('Loss/Valid', valid_loss, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-2sUheA4YSlf"
   },
   "outputs": [],
   "source": [
    "\"\"\" Создание и сохранение масок изображений из папки test\"\"\"\n",
    "it = 0\n",
    "for it in tqdm(range (100)):\n",
    "  \n",
    "  ind = str(it + 1460)\n",
    "  img = ds_valid[it][0].cuda()\n",
    "  mask = m(img.unsqueeze(0))\n",
    "  mask = mask.squeeze(0)\n",
    "  mask = mask.squeeze(0)\n",
    "  mask = custom_mask(mask)\n",
    "  mask1 = PIL.Image.fromarray(mask.astype('uint8'))\n",
    "  mask1.save(\"./pred_test/\" + ind + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f8IsfwjSIDcW"
   },
   "outputs": [],
   "source": [
    "\"\"\" Создание pred_valid_template.csv\"\"\"\n",
    "iter = 0\n",
    "data_len = ds_test.__len__()\n",
    "data1 = np.zeros(data_len*2)\n",
    "data1 = data1.reshape(data_len,2)\n",
    "data1 = data1.tolist()\n",
    "for iter in tqdm(range (data_len)):   \n",
    "  img = ds_test[iter][0].cuda()\n",
    "  mask = m(img.unsqueeze(0))\n",
    "  mask = mask.squeeze(0)\n",
    "  mask = mask.squeeze(0)\n",
    "  mask = custom_mask(mask)\n",
    "  data1[iter][0] = ds_test.files[iter].split(\".\")[0]\n",
    "  data1[iter][1] = encode_rle(mask)\n",
    "\n",
    "csv_writer(data1, \"./pred_valid_template.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OF8kYVffeKm7"
   },
   "outputs": [],
   "source": [
    "\"\"\" Создание html страницы \"\"\"\n",
    "\n",
    "paths_to_imgs = sorted(glob(\"./test/*\"))\n",
    "\n",
    "pred_masks = [np.array(Image.open(path)) for path in sorted(glob(\"./pred_test/*\"))]\n",
    "\n",
    "_ = get_html(paths_to_imgs, pred_masks, path_to_save=\"results/final\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of Hum_Seg.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
